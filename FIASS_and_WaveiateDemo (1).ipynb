{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GR-LnhxolwNR"
      },
      "outputs": [],
      "source": [
        "# ! pip install langchain pypdf\n",
        "# !pip install sentence-transformers==2.2.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install huggingface"
      ],
      "metadata": {
        "id": "yr5FOYWGmPuW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install faiss-cpu"
      ],
      "metadata": {
        "id": "TssZTD6UmdxO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tiktoken"
      ],
      "metadata": {
        "id": "VPJ4OnR2mnt2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "j8M51hCbmsBT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "QIq-LFVKm4x1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub"
      ],
      "metadata": {
        "id": "eROCJ4sXm8V6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HUGGINGFACEHUB_API_TOKEN = userdata.get('HUGGINGFACEHUB_API_TOKEN')\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "WEAVIATE_CLUSTER = userdata.get('WEAVIATE_CLUSTER')\n",
        "WEAVIATE_API_KEY = userdata.get('WEAVIATE_API_KEY')\n",
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN\n",
        "\n",
        "os.environ['WEAVIATE_CLUSTER'] = WEAVIATE_CLUSTER\n",
        "os.environ[\"WEAVIATE_API_KEY\"] = WEAVIATE_API_KEY"
      ],
      "metadata": {
        "id": "iPisJW75nXSJ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceHub\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "KCcS4n6KnfA4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the chain to answer questions\n",
        "llm=HuggingFaceHub(repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", model_kwargs={\"temperature\":0.9,\"max_length\":512})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DifPlOvlnjt_",
        "outputId": "89c74ef9-ae55-4b51-80a0-f31ed996bd01"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.huggingface_hub.HuggingFaceHub` was deprecated in langchain-community 0.0.21 and will be removed in 0.2.0. Use HuggingFaceEndpoint instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir pdfs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R98mm9AMnt6d",
        "outputId": "f8450b69-912b-4770-ac0a-2dc864010ee4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘pdfs’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFDirectoryLoader"
      ],
      "metadata": {
        "id": "3hf6D2HJnwGx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFDirectoryLoader(\"pdfs\")\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "XfsXdbsGoniL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "1x2D6kYjosPq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
        "text_chunks = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "YBtcAfgVo4JR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2wizNzio4Fp",
        "outputId": "203634a5-53c9-4c5f-dec3-a6d2cfbb3d8a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbDHQzTuo4DC",
        "outputId": "7c3e8f39-417f-484a-c2fc-7e8ba35d2cf7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='CS391R: Robot Learning (Fall 2021)3Importance of Object Detection for Robotics❖Visual modality is very powerful❖Humans are able to detect objects and do perception using just this modality in real time (not needing radar) ❖If we want responsive robot systems that work in real time (without specialized sensors) almost real time vision based object detection can help greatly\\nVision based vs LIDAR (self driving)\\nTesla Investor Day Presentation', metadata={'source': 'pdfs/yolo.pdf', 'page': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "R7KD_gA2o4A4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore= FAISS.from_documents(text_chunks,embeddings)"
      ],
      "metadata": {
        "id": "GwbuOBjRo3-c"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is yolo?\""
      ],
      "metadata": {
        "id": "KSyoWSPRo38A"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs=vectorstore.similarity_search(query, k=3)"
      ],
      "metadata": {
        "id": "vUL6Xotho35v"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpRYMzcyqu7A",
        "outputId": "885f045b-5047-42db-ea5f-f4266b5385c3"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='image each time leading to less false positives (has contextual information for detection) YOLO algorithm', metadata={'source': 'pdfs/yolo.pdf', 'page': 4}),\n",
              " Document(page_content='CS391R: Robot Learning (Fall 2021)20Discussion of Results❖Pro: YOLO is a lot faster than the other algorithms for image detection❖Pro: YOLO’s use of global information rather than only local information allows it to understand contextual information when doing object detection➢Does better in domains such as artwork due to this❖Con: YOLO lagged behind the SOTA models in object detection➢This is attributed to making many localization errors and unable to detect small object', metadata={'source': 'pdfs/yolo.pdf', 'page': 19}),\n",
              " Document(page_content='CS391R: Robot Learning (Fall 2021)2Problem Addressed: Object Detection❖Object detection is the problem of both locating ANDclassifying objects ❖Goal of YOLO algorithm is to do object detection both fast ANDwith high accuracy\\n“Deep Learning for Vision Systems” (Elgendy)Object Detection vs Classification', metadata={'source': 'pdfs/yolo.pdf', 'page': 1})]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "M3ubrOGHq9iy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever())"
      ],
      "metadata": {
        "id": "lq3AAarHrJyp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"for which type of algorithms Yolo is used?\""
      ],
      "metadata": {
        "id": "uS6WYygkrXA6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(qa.run(query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyHxFQoLr6eY",
        "outputId": "80157a7f-081a-44f4-92dd-ce16a3d286b7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "image each time leading to less false positives (has contextual information for detection) YOLO algorithm\n",
            "\n",
            "CS391R: Robot Learning (Fall 2021)20Discussion of Results❖Pro: YOLO is a lot faster than the other algorithms for image detection❖Pro: YOLO’s use of global information rather than only local information allows it to understand contextual information when doing object detection➢Does better in domains such as artwork due to this❖Con: YOLO lagged behind the SOTA models in object detection➢This is attributed to making many localization errors and unable to detect small object\n",
            "\n",
            "CS391R: Robot Learning (Fall 2021)15Experimental Setup❖Authors compare YOLO against the previous work described above on PASCAL VOC 2007, and VOC 2012 as well as out of domain art dataset ❖Correct if IOU metric above .5 and class is correct❖Use two performance metrics:➢mAP score: mean average precision➢FPS: frames per second❖Add FAST YOLO: which has less parameters\n",
            "\n",
            "but P(Object), lowers interpretability❖Another limitation of YOLO is that it imposed spatial constraints on the objects in the image since only B boxes can be predicted on an SxS grid❖Since the architecture only predicts boxes, this might make it less useful for irregular shapes\n",
            "\n",
            "Question: for which type of algorithms Yolo is used?\n",
            "Helpful Answer: Yolo is used for object detection algorithms in computer vision. It is particularly good for real-time object detection due to its high speed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"what are cons of yolo?\""
      ],
      "metadata": {
        "id": "lWNQhWqWsBYM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(qa.run(query))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcjHKkBFsTb6",
        "outputId": "5c259ec0-f4a4-4c00-a607-7c53a5972e6c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
            "\n",
            "but P(Object), lowers interpretability❖Another limitation of YOLO is that it imposed spatial constraints on the objects in the image since only B boxes can be predicted on an SxS grid❖Since the architecture only predicts boxes, this might make it less useful for irregular shapes\n",
            "\n",
            "image each time leading to less false positives (has contextual information for detection) YOLO algorithm\n",
            "\n",
            "CS391R: Robot Learning (Fall 2021)21Critique / Limitations / Open Issues ❖Performance lags behind SOTA ❖Requires data to be labeled with bounding boxes, hard to collect for many classes➢Previous work could generalize better since it used image classifier➢2014 COCO dataset (very large dataset) addressed this somewhat❖Regarding experiments: number of classes predicted is very limited➢Not convinced that YOLO v1 is generalizable ❖Confidence output of YOLO not confidence of class but P(Object),\n",
            "\n",
            "CS391R: Robot Learning (Fall 2021)15Experimental Setup❖Authors compare YOLO against the previous work described above on PASCAL VOC 2007, and VOC 2012 as well as out of domain art dataset ❖Correct if IOU metric above .5 and class is correct❖Use two performance metrics:➢mAP score: mean average precision➢FPS: frames per second❖Add FAST YOLO: which has less parameters\n",
            "\n",
            "Question: what are cons of yolo?\n",
            "Helpful Answer: Based on the provided context, the cons of YOLO are:\n",
            "1. Performance lags behind state-of-the-art.\n",
            "2. Requires data to be labeled with bounding boxes, which are hard to collect for many classes.\n",
            "3. The architecture only predicts boxes, which might make it less useful for irregular shapes.\n",
            "4. Has less false positives but at the cost of not being able to detect small objects.\n",
            "5. Limited number of classes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install weaviate-client"
      ],
      "metadata": {
        "id": "arlwWQBMsVNs"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install unstructured\n",
        "# !pip install \"unstructured[pdf]\""
      ],
      "metadata": {
        "id": "NuVIEw9zwAAE"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import weaviate\n",
        "from langchain.vectorstores import Weaviate\n",
        "\n",
        "#Connect to weaviate Cluster\n",
        "auth_config = weaviate.auth.AuthApiKey(api_key = WEAVIATE_API_KEY)\n",
        "WEAVIATE_URL = WEAVIATE_CLUSTER\n",
        "\n",
        "client = weaviate.Client(\n",
        "    url = WEAVIATE_URL,\n",
        "    additional_headers = {\"X-OpenAI-Api-key\": OPENAI_API_KEY},\n",
        "    auth_client_secret = auth_config,\n",
        "    startup_period = 10\n",
        ")"
      ],
      "metadata": {
        "id": "iDIMnGslyY0U"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.is_ready()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhwtahyDzlDw",
        "outputId": "180adb3b-da1a-4a3c-9245-846461d73aa4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define input structure\n",
        "client.schema.delete_all()\n",
        "client.schema.get()\n",
        "schema = {\n",
        "    \"classes\": [\n",
        "        {\n",
        "            \"class\": \"Chatbot\",\n",
        "            \"description\": \"Documents for chatbot\",\n",
        "            \"vectorizer\": \"text2vec-openai\",\n",
        "            \"moduleConfig\": {\"text2vec-openai\": {\"model\": \"ada\", \"type\": \"text\"}},\n",
        "            \"properties\": [\n",
        "                {\n",
        "                    \"dataType\": [\"text\"],\n",
        "                    \"description\": \"The content of the paragraph\",\n",
        "                    \"moduleConfig\": {\n",
        "                        \"text2vec-openai\": {\n",
        "                            \"skip\": False,\n",
        "                            \"vectorizePropertyName\": False,\n",
        "                        }\n",
        "                    },\n",
        "                    \"name\": \"content\",\n",
        "                },\n",
        "            ],\n",
        "        },\n",
        "    ]\n",
        "}\n",
        "\n",
        "client.schema.create(schema)\n",
        "vectorstore = Weaviate(client, \"Chatbot\", \"content\", attributes=[\"source\"])"
      ],
      "metadata": {
        "id": "Nk4S0N3t1GYR"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load text into the vectorstore\n",
        "text_meta_pair = [(doc.page_content, doc.metadata) for doc in text_chunks]\n",
        "texts, meta = list(zip(*text_meta_pair))\n",
        "vectorstore.add_texts(texts, meta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjdHUWW-1N3a",
        "outputId": "66d8238c-055f-4418-beae-7e1d8accf652"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n",
            "{'error': [{'message': 'update vector: connection to: OpenAI API failed with status: 401 error: Incorrect API key provided: hf_QGoyo*************************WPCt. You can find your API key at https://platform.openai.com/account/api-keys.'}]}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['89434192-f2c5-4c00-985f-cb43a05337a9',\n",
              " '229a7fb9-2e92-4438-8ad8-510f59ca30ed',\n",
              " '41a8d56f-bf4b-4b0d-9d06-b0da22e764c2',\n",
              " '1ab80c45-4ea4-4999-9e1a-322c168c1f2a',\n",
              " '18387bd5-c1b5-4049-80f4-d31bf8c2eb46',\n",
              " '02daf152-4e3a-4164-a2e7-6776621f9fe5',\n",
              " '3ec69445-4a10-4093-80bc-59f98f27d37c',\n",
              " '54a98499-30be-4b90-98c1-53ea9de45e90',\n",
              " '41e60a81-6416-4914-8012-8ef9854bb5ef',\n",
              " '94212c0f-0ef1-408f-9555-70d2df5e9230',\n",
              " '0a6e40cc-e969-4905-819d-a2f9c7e5c13b',\n",
              " 'bad680ce-39db-4a40-bb62-c16387a165a6',\n",
              " '613191fe-ab30-44e1-a4f5-fec863d0a34a',\n",
              " '56d96943-832f-4c97-8cb4-141a049fbed3',\n",
              " '5b819340-3df7-44a7-a212-a67746223342',\n",
              " '6ea93480-e5ff-41b5-ae85-5c1fe5c6acf1',\n",
              " 'd8d118d9-91a5-484b-aef2-aea478628970',\n",
              " '33b81866-8350-42ce-8a47-03427cf435ce',\n",
              " '5d9bc0b3-39f9-49ad-8428-5524c50b2e56',\n",
              " '07f8122b-0390-42cd-846f-76cff1b5eb24',\n",
              " 'c4c4fb9d-e202-4f7b-b7fd-54994ed8a8f3',\n",
              " '760b5eb4-ed6d-4b74-9511-a7ce223d9eda',\n",
              " '4a9663d5-5fcc-4c9a-ba96-2b28000ddc22',\n",
              " 'af1c5c40-e6d7-47f9-a97d-79b646b0413d',\n",
              " 'e8c2ce23-7cef-4adf-9409-db5016fdb28f',\n",
              " '284e4f26-d4d2-4530-9aa9-11d124f60b42',\n",
              " '1f5c0045-f20b-450c-81b9-367840ec61a8',\n",
              " 'bc3b08ea-992b-4fd2-bf86-56f0a2357aba',\n",
              " '53e7205d-57b0-41f6-97e9-8511c6e26175']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wpo9T1wy1arU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}